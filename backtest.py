import json
import sqlite3
import datetime
from collections import defaultdict, deque
import numpy as np
from sklearn.ensemble import IsolationForest

# æ¥å…¥ç‹¬ç«‹çš„ AI ç®—æ³•åº“
import ai_models

# ==========================================
# åŸºç¡€å­—å…¸æ¨ç®— (ä¿æŒä¸ä¸»ç¨‹åºå®Œå…¨ä¸€è‡´)
# ==========================================
def get_current_zodiac_map(ref_year):
    zodiac_order = ['é¼ ', 'ç‰›', 'è™', 'å…”', 'é¾', 'è›‡', 'é¦¬', 'ç¾Š', 'çŒ´', 'é›', 'ç‹—', 'è±¬']
    year = ref_year
    # ç®€åŒ–å¤„ç†ï¼šå‡è®¾ç«‹æ˜¥åˆ†ç•Œï¼Œæ­¤å¤„ä»¥åŸºå‡†å¹´ä»½è®¡ç®—
    base_year = 2020
    current_zodiac_idx = (year - base_year) % 12
    zodiac_map = {z: [] for z in zodiac_order}
    for num in range(1, 50):
        offset = (num - 1) % 12
        z_idx = (current_zodiac_idx - offset) % 12
        zodiac_map[zodiac_order[z_idx]].append(num)
    return zodiac_map

def get_current_wuxing_map(ref_year):
    nayin_cycle = ['é‡‘', 'ç«', 'æœ¨', 'åœŸ', 'é‡‘', 'ç«', 'æ°´', 'åœŸ', 'é‡‘', 'æœ¨',
                   'æ°´', 'åœŸ', 'ç«', 'æœ¨', 'æ°´', 'é‡‘', 'ç«', 'æœ¨', 'åœŸ', 'é‡‘',
                   'ç«', 'æ°´', 'åœŸ', 'é‡‘', 'æœ¨', 'æ°´', 'åœŸ', 'ç«', 'æœ¨', 'æ°´']
    wuxing_map = {'é‡‘': [], 'æœ¨': [], 'æ°´': [], 'ç«': [], 'åœŸ': []}
    for num in range(1, 50):
        target_year = ref_year - num + 1
        pair_index = (((target_year - 1984) % 60) + 60) % 60 // 2
        wuxing_map[nayin_cycle[pair_index]].append(num)
    return wuxing_map

def get_color_map():
    return {
        'çº¢': [1, 2, 7, 8, 12, 13, 18, 19, 23, 24, 29, 30, 34, 35, 40, 45, 46],
        'è“': [3, 4, 9, 10, 14, 15, 20, 25, 26, 31, 36, 37, 41, 42, 47, 48],
        'ç»¿': [5, 6, 11, 16, 17, 21, 22, 27, 28, 32, 33, 38, 39, 43, 44, 49]
    }

def get_records_from_db(db_path='lottery.db'):
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    cursor.execute("SELECT period, raw_time, numbers, zodiacs, special, special_zodiac FROM history ORDER BY period ASC") # æ³¨æ„ï¼šå›æµ‹éœ€æŒ‰æ—¶é—´æ­£åºæ’åˆ—
    rows = cursor.fetchall()
    conn.close()
    
    records = []
    for row in rows:
        records.append({
            "period": row[0],
            "date": row[1],
            "numbers": json.loads(row[2]),
            "zodiacs": json.loads(row[3]),
            "special": row[4],
            "special_zodiac": row[5]
        })
    return records

# ==========================================
# æ ¸å¿ƒå›æµ‹é€»è¾‘
# ==========================================
def run_backtest(test_window=20, db_file='lottery.db'):
    records = get_records_from_db(db_file)
    total_records = len(records)
    
    if total_records < test_window + 50:
        print("é”™è¯¯ï¼šæ•°æ®é‡ä¸è¶³ä»¥æ”¯æ’‘å›æµ‹çª—å£ä¸ç‰¹å¾å†·å¯åŠ¨è¦æ±‚ã€‚")
        return

    print(f"\n[{datetime.datetime.now().strftime('%H:%M:%S')}] å¼€å§‹æ‰§è¡Œé‡åŒ–å›æµ‹...")
    print(f"æ€»æ•°æ®é‡: {total_records} æœŸ | å›æµ‹çª—å£: è¿‘ {test_window} æœŸ")
    print("-" * 60)

    top1_hit_count = 0
    top6_hit_count = 0
    normal_hit_rates = []

    # æ­¥è¿›éªŒè¯å¾ªç¯ (Walk-Forward)
    for i in range(total_records - test_window, total_records):
        # 1. æˆªæ–­æ•°æ®ï¼šåªå–ç›®æ ‡æœŸä¹‹å‰çš„æ•°æ®ä½œä¸ºâ€œå†å²â€
        history_slice = records[:i]
        target_record = records[i]
        target_period = target_record['period']
        actual_special = target_record['special']
        actual_normals = set(target_record['numbers'])
        
        latest = history_slice[-1]
        ref_year = int(latest['date'][:4])
        
        ZODIAC_MAP = get_current_zodiac_map(ref_year)
        NUM_TO_ZODIAC = {n: z for z, nums in ZODIAC_MAP.items() for n in nums}
        WUXING_MAP = get_current_wuxing_map(ref_year)
        NUM_TO_WUXING = {n: w for w, nums in WUXING_MAP.items() for n in nums}
        COLOR_MAP = get_color_map()
        NUM_TO_COLOR = {n: c for c, nums in COLOR_MAP.items() for n in nums}

        RELATIONS = {
            'ä¸‰åˆ': {'é¼ ':['é¾','çŒ´'], 'ç‰›':['è›‡','é›'], 'è™':['é¦¬','ç‹—'], 'å…”':['è±¬','ç¾Š'], 'é¾':['é¼ ','çŒ´'], 'è›‡':['ç‰›','é›'], 'é¦¬':['è™','ç‹—'], 'ç¾Š':['å…”','è±¬'], 'çŒ´':['é¼ ','é¾'], 'é›':['ç‰›','è›‡'], 'ç‹—':['è™','é¦¬'], 'è±¬':['å…”','ç¾Š']},
            'å…­åˆ': {'é¼ ':'ç‰›', 'ç‰›':'é¼ ', 'è™':'è±¬', 'è±¬':'è™', 'å…”':'ç‹—', 'ç‹—':'å…”', 'é¾':'é›', 'é›':'é¾', 'è›‡':'çŒ´', 'çŒ´':'è›‡', 'é¦¬':'ç¾Š', 'ç¾Š':'é¦¬'},
            'æ­£å†²': {'é¼ ':'é¦¬', 'é¦¬':'é¼ ', 'ç‰›':'ç¾Š', 'ç¾Š':'ç‰›', 'è™':'çŒ´', 'çŒ´':'è™', 'å…”':'é›', 'é›':'å…”', 'é¾':'ç‹—', 'ç‹—':'é¾', 'è›‡':'è±¬', 'è±¬':'è›‡'},
            'å…­å®³': {'é¼ ':'ç¾Š', 'ç¾Š':'é¼ ', 'ç‰›':'é¦¬', 'é¦¬':'ç‰›', 'è™':'è›‡', 'è›‡':'è™', 'å…”':'é¾', 'é¾':'å…”', 'çŒ´':'è±¬', 'è±¬':'çŒ´', 'ç‹—':'é›', 'é›':'ç‹—'}
        }
        WUXING_SHENG = {'é‡‘':'æ°´', 'æ°´':'æœ¨', 'æœ¨':'ç«', 'ç«':'åœŸ', 'åœŸ':'é‡‘'}
        WUXING_KE = {'é‡‘':'æœ¨', 'æœ¨':'åœŸ', 'åœŸ':'æ°´', 'æ°´':'ç«', 'ç«':'é‡‘'}

        # 2. ç‰¹å¾å·¥ç¨‹æ„å»º (åŸºäºæˆªæ–­çš„å†å²æ•°æ®)
        miss_tracker = {n: 0 for n in range(1, 50)}
        freq_all = {n: 0 for n in range(1, 50)}
        recent_50_queue = deque(maxlen=50) 
        recent_30_queue = deque(maxlen=30) 
        running_trans_counts = defaultdict(lambda: defaultdict(int))
        running_trans_totals = defaultdict(int)

        X_train_data = [] 
        y_train_data = [] 
        
        iso_forest = IsolationForest(contamination=0.1, random_state=42)
        
        for j in range(len(history_slice) - 1):
            curr_draw = history_slice[j]
            next_draw = history_slice[j+1]
            
            curr_nums = set(curr_draw['numbers'] + [curr_draw['special']])
            next_nums = set(next_draw['numbers'] + [next_draw['special']])
            
            recent_50_queue.append(curr_nums)
            recent_30_queue.append(curr_nums)
            for n in curr_nums: freq_all[n] += 1
            for n in range(1, 50):
                if n in curr_nums: miss_tracker[n] = 0
                else: miss_tracker[n] += 1

            freq_recent_50 = {n: 0 for n in range(1, 50)}
            for past_nums in recent_50_queue:
                for n in past_nums: freq_recent_50[n] += 1
                    
            freq_10 = {n: 0 for n in range(1, 50)}
            freq_30 = {n: 0 for n in range(1, 50)}
            for past_nums in list(recent_30_queue)[-10:]:
                for n in past_nums: freq_10[n] += 1
            for past_nums in recent_30_queue:
                for n in past_nums: freq_30[n] += 1
                    
            last_special_zodiac = curr_draw['special_zodiac']
            last_special_wuxing = NUM_TO_WUXING.get(curr_draw['special'], 'é‡‘')
            sanhe = RELATIONS['ä¸‰åˆ'].get(last_special_zodiac, [])
            liuhe = RELATIONS['å…­åˆ'].get(last_special_zodiac, '')
            zhengchong = RELATIONS['æ­£å†²'].get(last_special_zodiac, '')
            liuhai = RELATIONS['å…­å®³'].get(last_special_zodiac, '')

            for n in range(1, 50):
                z = NUM_TO_ZODIAC.get(n, '')
                w = NUM_TO_WUXING.get(n, '')
                c = NUM_TO_COLOR.get(n, 'ç»¿')
                zodiac_rel_val = 1 if z in sanhe or z == liuhe else (-1 if z == zhengchong or z == liuhai else 0)
                wuxing_rel_val = 1 if WUXING_SHENG.get(last_special_wuxing) == w else (-1 if WUXING_KE.get(last_special_wuxing) == w else 0)
                color_val = 1 if c == 'çº¢' else (2 if c == 'è“' else 3) 
                macd_val = (freq_10[n] / 10.0) - (freq_30[n] / 30.0) if len(recent_30_queue) >= 30 else 0
                markov_prob = running_trans_counts[last_special_zodiac][z] / running_trans_totals[last_special_zodiac] if running_trans_totals[last_special_zodiac] > 0 else 0.0
                
                feat = [
                    miss_tracker[n], freq_all[n], freq_recent_50[n], macd_val, markov_prob,                
                    1 if n >= 25 else 0, 1 if n % 2 != 0 else 0, zodiac_rel_val, wuxing_rel_val, color_val
                ]
                X_train_data.append(feat)
                y_train_data.append(1 if n in next_nums else 0)
                
            running_trans_counts[curr_draw['special_zodiac']][next_draw['special_zodiac']] += 1
            running_trans_totals[curr_draw['special_zodiac']] += 1

        iso_forest.fit(X_train_data)
        anomaly_scores = iso_forest.decision_function(X_train_data)
        for idx in range(len(X_train_data)):
            X_train_data[idx].append(anomaly_scores[idx])

        # æ„å»ºå¾…é¢„æµ‹çš„æœ€æ–°ä¸€æœŸç‰¹å¾
        latest_nums = set(latest['numbers'] + [latest['special']])
        recent_50_queue.append(latest_nums)
        recent_30_queue.append(latest_nums)
        for n in latest_nums: freq_all[n] += 1
        for n in range(1, 50):
            if n in latest_nums: miss_tracker[n] = 0
            else: miss_tracker[n] += 1

        freq_recent_50 = {n: 0 for n in range(1, 50)}
        for past_nums in recent_50_queue:
            for n in past_nums: freq_recent_50[n] += 1
                
        freq_10 = {n: 0 for n in range(1, 50)}
        freq_30 = {n: 0 for n in range(1, 50)}
        for past_nums in list(recent_30_queue)[-10:]:
            for n in past_nums: freq_10[n] += 1
        for past_nums in recent_30_queue:
            for n in past_nums: freq_30[n] += 1

        reversed_hist = history_slice[::-1]
        recent_10_big = sum(1 for r in reversed_hist[:10] for n in r['numbers']+[r['special']] if n >= 25)
        recent_10_odd = sum(1 for r in reversed_hist[:10] for n in r['numbers']+[r['special']] if n % 2 != 0)
        big_bias = (recent_10_big / 70.0) - 0.5
        odd_bias = (recent_10_odd / 70.0) - 0.5
        
        last_special_zodiac = latest['special_zodiac']
        last_special_wuxing = NUM_TO_WUXING.get(latest['special'], 'é‡‘')
        sanhe = RELATIONS['ä¸‰åˆ'].get(last_special_zodiac, [])
        liuhe = RELATIONS['å…­åˆ'].get(last_special_zodiac, '')
        zhengchong = RELATIONS['æ­£å†²'].get(last_special_zodiac, '')
        liuhai = RELATIONS['å…­å®³'].get(last_special_zodiac, '')

        X_predict_data = []
        for n in range(1, 50):
            z = NUM_TO_ZODIAC.get(n, '')
            w = NUM_TO_WUXING.get(n, '')
            c = NUM_TO_COLOR.get(n, 'ç»¿')
            zodiac_rel_val = 1 if z in sanhe or z == liuhe else (-1 if z == zhengchong or z == liuhai else 0)
            wuxing_rel_val = 1 if WUXING_SHENG.get(last_special_wuxing) == w else (-1 if WUXING_KE.get(last_special_wuxing) == w else 0)
            color_val = 1 if c == 'çº¢' else (2 if c == 'è“' else 3)
            macd_val = (freq_10[n] / 10.0) - (freq_30[n] / 30.0) if len(recent_30_queue) >= 30 else 0
            markov_prob = running_trans_counts[last_special_zodiac][z] / running_trans_totals[last_special_zodiac] if running_trans_totals[last_special_zodiac] > 0 else 0.0
            
            feat = [
                miss_tracker[n], freq_all[n], freq_recent_50[n], macd_val, markov_prob,
                1 if n >= 25 else 0, 1 if n % 2 != 0 else 0, zodiac_rel_val, wuxing_rel_val, color_val
            ]
            X_predict_data.append(feat)

        curr_anomaly_scores = iso_forest.decision_function(X_predict_data)
        for idx in range(len(X_predict_data)):
            X_predict_data[idx].append(curr_anomaly_scores[idx])

        # 3. è°ƒç”¨ AI ç®—æ³•æ¨¡å— (é™é»˜è¾“å‡ºä»¥é¿å…åˆ·å±)
        import sys, os
        original_stdout = sys.stdout
        sys.stdout = open(os.devnull, 'w') # ä¸´æ—¶å±è”½ ai_models å†…éƒ¨çš„ print 
        ensemble_probabilities = ai_models.get_ensemble_probabilities(X_train_data, y_train_data, X_predict_data)
        sys.stdout = original_stdout # æ¢å¤è¾“å‡º

        # 4. åæ€è¡¥å¿ä¸æ‰“åˆ†
        scores = defaultdict(float)
        for n in range(1, 50):
            if n in latest_nums:
                continue

            base_score = ensemble_probabilities[n-1] * 100
            is_big = 1 if n >= 25 else 0
            is_odd = 1 if n % 2 != 0 else 0
            macd_val = X_predict_data[n-1][3]
            
            if big_bias > 0.05 and not is_big: base_score += 1.5
            elif big_bias < -0.05 and is_big: base_score += 1.5
            if odd_bias > 0.05 and not is_odd: base_score += 1.5
            elif odd_bias < -0.05 and is_odd: base_score += 1.5

            continuous_fingerprint = (miss_tracker[n] * 0.033) + (freq_all[n] * 0.011) - (freq_recent_50[n] * 0.04) + (macd_val * 0.05)
            scores[n] = base_score + continuous_fingerprint

        # 5. æå–é¢„æµ‹ç»“æœ
        sorted_scores = sorted(scores.items(), key=lambda x: x[1], reverse=True)
        top6_specials = [item[0] for item in sorted_scores[:6]]
        primary_special = top6_specials[0]
        
        normal_candidates = []
        for num, _ in sorted_scores:
            if num == primary_special: continue
            normal_candidates.append(num)
            if len(normal_candidates) >= 6: break

        # 6. å¯¹æ¯”çœŸå®ç»“æœè¿›è¡Œè¯„åˆ¤
        is_top1_hit = (actual_special == primary_special)
        is_top6_hit = (actual_special in top6_specials)
        normal_hit_count = len(set(normal_candidates).intersection(actual_normals))
        
        if is_top1_hit: top1_hit_count += 1
        if is_top6_hit: top6_hit_count += 1
        normal_hit_rates.append(normal_hit_count)

        # æ‰“å°å•æœŸå›æµ‹æ—¥å¿—
        hit_status = "ğŸ¯ TOP1ç²¾ç¡®å‘½ä¸­" if is_top1_hit else ("âœ… TOP6çŸ©é˜µå‘½ä¸­" if is_top6_hit else "âŒ æœªå‘½ä¸­")
        print(f"| æœŸæ•°: {target_period} | çœŸå®ç‰¹ç : {actual_special:02d} | é¢„æµ‹Top6: {[f'{n:02d}' for n in top6_specials]} | çŠ¶æ€: {hit_status} | æ­£ç é˜²å®ˆå‘½ä¸­: {normal_hit_count}/6")

    # ==========================================
    # è¾“å‡ºé‡åŒ–è¯„ä¼°æŠ¥å‘Š
    # ==========================================
    print("-" * 60)
    print("ğŸ“Š [é‡åŒ–å›æµ‹æ€»ç»“æŠ¥å‘Š]")
    print(f"æµ‹è¯•æ ·æœ¬é‡: {test_window} æœŸ")
    print(f"é¦–é€‰ç‰¹ç å‘½ä¸­ç‡ (Top 1): {top1_hit_count} / {test_window}  ({(top1_hit_count/test_window)*100:.2f}%)")
    print(f"æ ¸å¿ƒçŸ©é˜µå‘½ä¸­ç‡ (Top 6): {top6_hit_count} / {test_window}  ({(top6_hit_count/test_window)*100:.2f}%)")
    print(f"æ­£ç é˜²å®ˆå¹³å‡å‘½ä¸­æ•°: {np.mean(normal_hit_rates):.2f} / 6")
    print("-" * 60)

if __name__ == '__main__':
    # é»˜è®¤å›æµ‹æœ€è¿‘ 20 æœŸï¼Œå¯è‡ªè¡Œä¿®æ”¹å‚æ•°
    run_backtest(test_window=20)